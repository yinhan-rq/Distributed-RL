# ---- MAPPO 训练参数 ----

env_name: "sysu_3_vs_2"
learner: "mappo_learner"
num_env_steps: 10000
seed: 6
gamma: 0.99
lr: 3.0e-4
critic_lr: 3.0e-4
opti_eps: 1.0e-5 #优化器RMSprop 的epsilon
weight_decay: 0
thread_num: 1
episode_length: 400
eval_episode_length: 400  
left_agent_num: 3
right_agent_num: 2

#R_Critic R_Actor
gain: 0.01
use_orthogonal: True
use_policy_active_masks: True 
use_naive_recurrent_policy: False
use_recurrent_policy: False
# ---------------

#CNN-------------
use_ReLU: True
# ---------------

#MLP-------------
use_feature_normalization : True
stacked_frames : 1
layer_N : 1
# ---------------

#PPOTrainer------
clip_param : 0.2
ppo_epoch : 6
num_mini_batch : 4
data_chunk_length : 10
value_loss_coef : 1
entropy_coef : 0.01
max_grad_norm : 10.0
huber_delta : 10.0

use_recurrent_policy : False
use_naive_recurrent : False
use_max_grad_norm : True
use_clipped_value_loss : True
use_huber_loss : True
use_value_active_masks : True
use_policy_active_masks : True

# ---------------

gae_lambda: 0.95
use_gae: False
use_popart: False
use_valuenorm: False
use_proper_time_limits: False
hidden_size: 64
recurrent_N: 1

use_centralized_V: True
use_linear_lr_decay: False

save_interval: 100
use_eval: False
eval_interval: 90
log_interval: 1
eval_episode_num: 1
# ---- BUFFER ----

#----- imitation learning-----
use_gail: False
expert_buffer_size: 1000000
agent_num: 11
gail_epoch: 10
gail_batch_size: 200
gail_exp_batch_size: 400
D_lr: 1.0e-4
imi_reward_weight: 0.4
IL_buffer_path: "./data/3vs2_test.pt"
reward_clip: 0.5