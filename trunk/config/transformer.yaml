#---- MAPPO 训练参数 ----

env_name: "football_11_vs_11_stochastic_2"
learner: "mat_learner"
trainer: "mappo"
device: "cuda:3"
num_env_steps: 1000000
episode_length: 200
seed: 6
gamma: 0.99
lr: 5.0e-4
critic_lr: 5.0e-4
opti_eps: 1.0e-5 #优化器RMSprop 的epsilon
weight_decay: 0
thread_num: 2
eval_episode_length: 3000  
left_agent_num: 11
right_agent_num: 11

#CNN-------------
use_ReLU: True
# ---------------

#MLP-------------
use_feature_normalization : True
stacked_frames : 1
layer_N : 1
# ---------------

#PPOTrainer------
clip_param : 0.05
ppo_epoch : 10
num_mini_batch : 4
data_chunk_length : 10
value_loss_coef : 1
entropy_coef : 0.01
max_grad_norm : 0.5
huber_delta : 10.0

use_naive_recurrent : False
use_max_grad_norm : True
use_clipped_value_loss : True
use_huber_loss : True
use_value_active_masks : True
use_policy_active_masks : True

# ---------------

gae_lambda: 0.95
use_gae: True
use_popart: False
use_valuenorm: False
use_proper_time_limits: False
hidden_size: 64
recurrent_N: 1

use_centralized_V: True
use_linear_lr_decay: False

save_interval: 100
use_eval: True
eval_interval: 90
log_interval: 1
eval_episode_num: 4
# ---- BUFFER ----

#----- imitation learning-----
use_gail: False
expert_buffer_size: 1000000
agent_num: 11
gail_epoch: 100
gail_batch_size: 200
D_lr: 1.0e-4
imi_reward_weight: 0.03
IL_buffer_path: "./data/ILbuffer_test.pt"

#------ self play ------
step_passed: 30000   # 小于这个步数不会存档
step_passed2: 500000  # 大于这个步数必定存档
training_time: 36000    # 自博弈时间
main_agents: 5
main_exploiters: 0
league_exploiters: 0
#-----------------------

#Transformer-----------------
encode_state: False
n_block: 1
n_embd: 64
n_head: 1
dec_actor: False
share_actor: False
#----------------------------